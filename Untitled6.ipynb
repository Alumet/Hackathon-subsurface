{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "\n",
    "import tsfresh\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import settings, ComprehensiveFCParameters, EfficientFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../SUHA_Paris2017/conBR_ir031_tostack.rsf@',\n",
       " '../SUHA_Paris2017/conBR_ir035_tostack.rsf@',\n",
       " '../SUHA_Paris2017/conBR_ir039_tostack.rsf@',\n",
       " '../SUHA_Paris2017/conBR_ir043_tostack.rsf@',\n",
       " '../SUHA_Paris2017/conBR_ir048_tostack.rsf@',\n",
       " '../SUHA_Paris2017/conBR_ir052_tostack.rsf@',\n",
       " '../SUHA_Paris2017/conBR_ir056_tostack.rsf@',\n",
       " '../SUHA_Paris2017/conBR_ir029_tostack.rsf@',\n",
       " '../SUHA_Paris2017/conBR_ir060_tostack.rsf@',\n",
       " '../SUHA_Paris2017/conBR_ir064_tostack.rsf@']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../SUHA_Paris2017\"\n",
    "\n",
    "all_files = [path + \"/\" + f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "start = 29 # part * int(len(all_files) / nb_part)\n",
    "stop = 69 # (part + 1) * int(len(all_files) / nb_part)\n",
    "some_files = all_files[start:stop:4]\n",
    "some_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1_convH = 75\n",
    "n2_convH = 5400\n",
    "n3_convH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Charger le fichier de données\n",
    "    \"\"\"\n",
    "    n_elems = n1_convH * n2_convH * n3_convH\n",
    "    f = open(filename, \"rb\")\n",
    "    data = struct.unpack('f' * n_elems, f.read(4 * n_elems))\n",
    "    f.close()\n",
    "    return np.reshape(data, (n3_convH, n2_convH, n1_convH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convH = load_data(all_files[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_signals(data):\n",
    "    \"\"\"\n",
    "    Normaliser le signal par rapport au temps\n",
    "    \"\"\"\n",
    "    for receiver in range(n3_convH):\n",
    "        for trace in range(n2_convH):\n",
    "            data[receiver, trace] = data[receiver, trace, :] / np.amax(data[receiver, trace], axis=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_convH = normalize_signals(convH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_sums(data, n_tracesByGroups=20):\n",
    "    \"\"\"\n",
    "    Calculer la somme des traces par groupe de 20\n",
    "    \"\"\"\n",
    "    n3, n2, n1 = data.shape\n",
    "    n_groups = int(n2 / n_tracesByGroups)\n",
    "\n",
    "    sum_traces_grouped = np.zeros((n3, n_groups, n1))\n",
    "    sum_traces = np.zeros((n3, n1))\n",
    "    \n",
    "    for receiver in range(n3):\n",
    "        traces = data[receiver]\n",
    "        sum_traces[receiver, :] = traces.sum(axis=0) / np.amax(np.abs(traces.sum(axis=0)))\n",
    "        for n_group in range(n_groups):\n",
    "            start = n_tracesByGroups * n_group\n",
    "            stop = n_tracesByGroups * (n_group + 1)\n",
    "            sum_traces_grouped[receiver, n_group, :] = traces[start:stop, :].sum(axis=0) / np.amax(np.abs(traces[start:stop, :].sum(axis=0)))\n",
    "    \n",
    "    return sum_traces, sum_traces_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelize(sumH, receiver):\n",
    "    \"\"\"\n",
    "    Etiquetter l'échantillon\n",
    "    \"\"\"\n",
    "    decision = np.median(sumH[receiver]) # 2.5\n",
    "    y_todf = np.zeros(sumH[receiver].shape)\n",
    "    y_todf = y_todf + (sumH[receiver] < decision).astype(np.int)\n",
    "    return pd.DataFrame(y_todf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractFeatures(sum_traces_grouped, receiver, main_features=None):\n",
    "    \"\"\"\n",
    "    Extraire les caractéristiques pour chaque récepteur\n",
    "    \"\"\"\n",
    "    master_df = pd.DataFrame(sum_traces_grouped[receiver, 0])\n",
    "    master_df['id'] = 0\n",
    "    for ii in range(1, sum_traces_grouped.shape[1]):\n",
    "        temp_df = pd.DataFrame(sum_traces_grouped[receiver, ii])\n",
    "        temp_df['id'] = ii\n",
    "        master_df = pd.DataFrame(np.vstack([master_df, temp_df]))\n",
    "    # 75 * 270 -1 = 20 249\n",
    "    \n",
    "    extraction_settings = EfficientFCParameters()\n",
    "    extraction_settings.IMPUTE = impute # Interpolation pour éviter les valeurs NaN\n",
    "    \n",
    "    kind_to_fc_parameters = {}\n",
    "    if main_features !=None:\n",
    "        kind_to_fc_parameters = load_obj(main_features)\n",
    "    \n",
    "    return extract_features(master_df, column_id=1,\n",
    "                            default_fc_parameters=extraction_settings,\n",
    "                            kind_to_fc_parameters=kind_to_fc_parameters).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_SSE(u_vgt, u):\n",
    "    \"\"\"\n",
    "    Calculer la somme de l'écart quadratique\n",
    "    \"\"\"\n",
    "    n3, n2, n1 = u.shape\n",
    "    SSE = np.zeros((n3, n2))\n",
    "    for receiver in range(n3):\n",
    "        for group in range(n2):\n",
    "            SSE[receiver, group] = np.square(u_vgt[receiver] - u[receiver, group, :]).sum()\n",
    "    return SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitPredictAllReceivers(receivers, sumH, sum_traces_grouped, traces, echantillonage=2, debug=True):\n",
    "    \"\"\"\n",
    "    Entraîner et prédire un classifieur pour chaque récepteur\n",
    "    \"\"\"\n",
    "    result = np.zeros((int(len(receivers) / echantillonage), 75))\n",
    "    \n",
    "    for receiver in receivers:\n",
    "        if receiver % echantillonage == 0:\n",
    "            print(\"Recepteur %d\" %(receiver))\n",
    "            y = labelize(sumH, receiver)\n",
    "            X = extractFeatures(sum_traces_grouped, receiver, \"main_features\")\n",
    "            new_X = extractFeatures(traces, receiver, \"main_features\")\n",
    "\n",
    "            clf = ExtraTreesClassifier(n_estimators=200)\n",
    "            clf.fit(X, y)\n",
    "            new_y = clf.predict(new_X)\n",
    "            \n",
    "            result[int(receiver / echantillonage)] = np.sum(traces[receiver, ii, :] for ii in range(traces[receiver].shape[0]) if not new_y[ii])\n",
    "            \n",
    "            \n",
    "            if debug:\n",
    "                y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "                classification_metrics(y, y_pred)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitPredictAllFiles(files, n_tracesByGroups=20, echantillonage=2, debug=True):\n",
    "    \"\"\"\n",
    "    Entraîner et prédire un classifieur pour chaque récepteur des fichiers\n",
    "    \"\"\"\n",
    "    \n",
    "    for indice, file in enumerate(files):\n",
    "        print(\"Fichier %s\" %(file))\n",
    "        convH = load_data(file)\n",
    "        n_convH = normalize_signals(convH)\n",
    "        sum_traces, sum_traces_grouped = compute_sums(n_convH, n_tracesByGroups)\n",
    "        sumH = compute_SSE(sum_traces, sum_traces_grouped)\n",
    "        \n",
    "        result=fitPredictAllReceivers(range(n3_convH), sumH, sum_traces_grouped,\n",
    "                               n_convH, echantillonage, debug=debug)\n",
    "        \n",
    "        result.astype('float32').tofile('result_' + str(indice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier ../SUHA_Paris2017/conBR_ir031_tostack.rsf@\n",
      "Recepteur 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:04<00:00, 55.20it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:50<00:00, 106.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 110.32it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:48<00:00, 111.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 108.27it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:47<00:00, 113.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 99.59it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:53<00:00, 100.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 102.55it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:50<00:00, 106.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 104.99it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:48<00:00, 110.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 107.25it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:48<00:00, 111.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 109.56it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:48<00:00, 112.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 98.34it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:48<00:00, 110.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 106.96it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:49<00:00, 109.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier ../SUHA_Paris2017/conBR_ir035_tostack.rsf@\n",
      "Recepteur 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 106.38it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:48<00:00, 110.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 108.97it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:48<00:00, 111.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 106.46it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:49<00:00, 109.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 108.27it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:50<00:00, 107.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 97.58it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:49<00:00, 109.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 107.27it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:50<00:00, 106.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:03<00:00, 84.68it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:50<00:00, 107.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 110.43it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:51<00:00, 105.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 110.24it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:48<00:00, 111.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:02<00:00, 108.96it/s]\n",
      "Feature Extraction: 100%|██████████| 5400/5400 [00:50<00:00, 107.82it/s] \n"
     ]
    }
   ],
   "source": [
    "fitPredictAllFiles(some_files[0:2], n_tracesByGroups=20, echantillonage=10, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
