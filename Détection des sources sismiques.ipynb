{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection des sources sismiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"SUHA_Paris2017\"\n",
    "part = 0 # choisir parmi 0, 1, 2, 3, 4\n",
    "nb_part = 5\n",
    "\n",
    "all_files = [path + \"/\" + f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "start = part * int(len(all_files) / nb_part)\n",
    "stop = (part + 1) * int(len(all_files) / nb_part)\n",
    "some_files = all_files[start:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1_convH = 75\n",
    "n2_convH = 5400\n",
    "n3_convH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Charger le fichier de données\n",
    "    \"\"\"\n",
    "    n_elems = n1_convH * n2_convH * n3_convH\n",
    "    f = open(filename, \"rb\")\n",
    "    data = struct.unpack('f' * n_elems, f.read(4 * n_elems))\n",
    "    f.close()\n",
    "    return np.reshape(data, (n3_convH, n2_convH, n1_convH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convH = load_data(all_files[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_signals(data):\n",
    "    \"\"\"\n",
    "    Normaliser le signal par rapport au temps\n",
    "    \"\"\"\n",
    "    for receiver in range(n3_convH):\n",
    "        for trace in range(n2_convH):\n",
    "            data[receiver, trace] = data[receiver, trace, :] / np.amax(data[receiver, trace], axis=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_convH = normalize_signals(convH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des traces sismiques après convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "receiver = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.imshow(n_convH[receiver].T, cmap='gray', aspect=\"auto\")\n",
    "plt.xlabel(\"Trace sismique après convolution\")\n",
    "plt.ylabel(\"Temps (en 20 ms)\")\n",
    "plt.title(\"Trace sismique après convolution pour un récepteur\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_sums(data, n_tracesByGroups=20):\n",
    "    \"\"\"\n",
    "    Calculer la somme des traces par groupe de 20\n",
    "    \"\"\"\n",
    "    n3, n2, n1 = data.shape\n",
    "    n_groups = int(n2 / n_tracesByGroups)\n",
    "\n",
    "    sum_traces_grouped = np.zeros((n3, n_groups, n1))\n",
    "    sum_traces = np.zeros((n3, n1))\n",
    "    \n",
    "    for receiver in range(n3):\n",
    "        traces = data[receiver]\n",
    "        sum_traces[receiver, :] = traces.sum(axis=0) / np.amax(np.abs(traces.sum(axis=0)))\n",
    "        for n_group in range(n_groups):\n",
    "            start = n_tracesByGroups * n_group\n",
    "            stop = n_tracesByGroups * (n_group + 1)\n",
    "            sum_traces_grouped[receiver, n_group, :] = traces[start:stop, :].sum(axis=0) / np.amax(np.abs(traces[start:stop, :].sum(axis=0)))\n",
    "    \n",
    "    return sum_traces, sum_traces_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_SSE(u_vgt, u):\n",
    "    \"\"\"\n",
    "    Calculer la somme de l'écart quadratique\n",
    "    \"\"\"\n",
    "    n3, n2, n1 = u.shape\n",
    "    SSE = np.zeros((n3, n2))\n",
    "    for receiver in range(n3):\n",
    "        for group in range(n2):\n",
    "            SSE[receiver, group] = np.square(u_vgt[receiver] - u[receiver, group, :]).sum()\n",
    "    return SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_traces, sum_traces_grouped = compute_sums(n_convH, n_tracesByGroups=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.imshow(sum_traces.T, cmap='gray', aspect=\"auto\")\n",
    "plt.xlabel(\"Récepteurs\")\n",
    "plt.ylabel(\"Temps (en 20 ms)\")\n",
    "plt.title(\"Somme des traces sismiques après convolution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sumH = compute_SSE(sum_traces, sum_traces_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(sumH[receiver], 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquettage des traces sismiques groupées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classe 0: la trace sismique groupée ressemble à la sommation des traces sismiques sur 6 heures\n",
    "- Classe 1: la trace sismique groupée ne ressemble pas à la sommation des traces sismiques sur 6 heures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "receiver = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelize(sumH, receiver):\n",
    "    \"\"\"\n",
    "    Etiquetter l'échantillon\n",
    "    \"\"\"\n",
    "    decision = np.median(sumH[receiver]) # 2.5\n",
    "    y_todf = np.zeros(sumH[receiver].shape)\n",
    "    y_todf = y_todf + (sumH[receiver] < decision).astype(np.int)\n",
    "    return pd.DataFrame(y_todf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = labelize(sumH, receiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction des caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractFeatures(sum_traces_grouped, receiver):\n",
    "    \"\"\"\n",
    "    Extraire les caractéristiques pour chaque récepteur\n",
    "    \"\"\"\n",
    "    master_df = pd.DataFrame(sum_traces_grouped[receiver, 0])\n",
    "    master_df['id'] = 0\n",
    "    for ii in range(1, sum_traces_grouped.shape[1]):\n",
    "        temp_df = pd.DataFrame(sum_traces_grouped[receiver, ii])\n",
    "        temp_df['id'] = ii\n",
    "        master_df = pd.DataFrame(np.vstack([master_df, temp_df]))\n",
    "    # 75 * 270 -1 = 20 249\n",
    "    \n",
    "    extraction_settings = ComprehensiveFCParameters()\n",
    "    extraction_settings.IMPUTE = impute # Interpolation pour éviter les valeurs NaN\n",
    "    return extract_features(master_df, column_id=1, default_fc_parameters=extraction_settings).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time X = extractFeatures(sum_traces_grouped, receiver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premiers modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_metrics(y, y_pred):\n",
    "    \"\"\"\n",
    "    Métriques de classification\n",
    "    \"\"\"\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Méthodes d'ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "%time y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "classification_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "clf = BaggingClassifier(tree, n_estimators=200)\n",
    "%time y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "classification_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "%time y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "classification_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=200)\n",
    "%time y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "classification_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_cross_val_predict(params, X, y, cv=10):\n",
    "    \"\"\"\n",
    "    Cross validation avec Xgboost\n",
    "    \"\"\"\n",
    "    dX = xgb.DMatrix(X.values, label=y.values)\n",
    "\n",
    "    n, p = X.shape\n",
    "    print(n, p)\n",
    "    \n",
    "    bst = xgb.train(params, dX, num_round)\n",
    "\n",
    "    preds = bst.predict(dX)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic'}\n",
    "num_round = 2\n",
    "%time y_pred = xgb_cross_val_predict(params, X, y, cv=10)\n",
    "# classification_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(300, 50, 100),\n",
    "                  activation='relu', solver='adam', max_iter=500, early_stopping=False)\n",
    "%time y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "classification_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine à vecteur support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = SVC(C=0.5, kernel='rbf', degree=3)\n",
    "%time y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "classification_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xgboost.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance des caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explicability(weights, columns, first=10):\n",
    "    \"\"\"\n",
    "    Représenter le poids des variables explicatives\n",
    "    \"\"\"\n",
    "    weights = weights.reshape(-1)\n",
    "    idx = weights.argsort()[::-1][:first]\n",
    "    x = np.arange(first)\n",
    "    y = weights[idx]\n",
    "    labels = columns[idx]\n",
    "\n",
    "    plt.close('all')\n",
    "    fig, ax = plt.subplots(figsize=(18, 4))\n",
    "\n",
    "    ax.bar(x, y, width=0.5, align='center')\n",
    "    ax.set_xlabel(u\"Variables explicatives\")\n",
    "    ax.set_ylabel(u\"Poids\")\n",
    "\n",
    "    plt.xticks(x, labels, rotation=80)\n",
    "    plt.title(u\"Poids des variables explicatives\")\n",
    "    plt.show()\n",
    "    \n",
    "    filename = \"features_weights.csv\"\n",
    "    features_weights = []\n",
    "    with open(filename, 'w') as f:\n",
    "        for x in zip(labels, y):\n",
    "            f.write(x[0])\n",
    "            f.write(\"\\t\")\n",
    "            f.write(str(x[1]))\n",
    "            f.write(\"\\n\")\n",
    "            features_weights.append(x)\n",
    "    return features_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_with_components(clf, X, y, columns, weights, cv=10):\n",
    "    \"\"\"\n",
    "    Calculer les scores en fonction du nombre de composants\n",
    "    \"\"\"\n",
    "    dict_feat_import = {\n",
    "        'feature_names': list(columns),\n",
    "        'feat_importance': list(weights)\n",
    "    }\n",
    "\n",
    "    feat_import_df = pd.DataFrame.from_dict(dict_feat_import, orient='columns')\n",
    "    sort_feat_import_df = feat_import_df.sort_values(by=['feat_importance'],ascending=[0]).reset_index(drop=True)\n",
    "    sorted_vect_importance = np.sort(weights, kind='heapsort')\n",
    "\n",
    "    sorted_vect_importance[:] = sorted_vect_importance[::-1]\n",
    "    score_mean = []\n",
    "    error_on_mean_score = []\n",
    "    n_th_most_important_features = []\n",
    "    last_included_feat = []\n",
    "    df_X = pd.DataFrame(X, columns=columns)\n",
    "    df_y = pd.DataFrame(y)\n",
    "\n",
    "    n_split_cv_n_fold = cv\n",
    "\n",
    "    for ind in range(sort_feat_import_df.shape[0]):\n",
    "        if ind % 10 == 0:\n",
    "            print('ind = ' + ind.__str__())\n",
    "\n",
    "        # print(\"Variables explicatives:\")\n",
    "        # print(list(sort_feat_import_df['feature_names'].head(ind+1)))\n",
    "        last_included_feat.append(list(sort_feat_import_df['feature_names'].head(ind+1))[-1])\n",
    "        X_new = df_X[list(sort_feat_import_df['feature_names'].head(ind+1))]\n",
    "\n",
    "        # print(X_new.shape)\n",
    "        # print(\"X_new.shape\")\n",
    "        # print('cross val...')\n",
    "\n",
    "        scores = cross_val_score(clf, X_new, np.ravel(df_y), cv=n_split_cv_n_fold, n_jobs=-1)\n",
    "        # print(np.std(scores))\n",
    "        error_on_mean_score.append(np.std(scores) / np.sqrt(n_split_cv_n_fold - 1))\n",
    "        # print(\"std scores\")\n",
    "        # print(np.mean(scores))\n",
    "        score_mean.append(np.mean(scores))\n",
    "        n_th_most_important_features.append(ind+1)\n",
    "\n",
    "        # print(\"mean scores\")\n",
    "\n",
    "        # print('************* \\n last included feature and score')\n",
    "        \"\"\"for a in range(len(last_included_feat)):\n",
    "            print(last_included_feat[a] + u\"\\u0009\"*4+'  -->  mean score  :  ' + score_mean[a].__str__())\"\"\"\n",
    "        # print('************* \\n last included feature and score (above)')\n",
    "\n",
    "        # print('******************** \\n')\n",
    "    return n_th_most_important_features, score_mean, error_on_mean_score, sort_feat_import_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_score_with_components(n_th_most_important_features, score_mean,\n",
    "                               error_on_mean_score, sort_feat_import_df):\n",
    "    \"\"\"\n",
    "    Tracer les scores en fonction du nombre de composants\n",
    "    \"\"\"\n",
    "    x = n_th_most_important_features\n",
    "    y = score_mean\n",
    "    yerr = error_on_mean_score\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.close('all')\n",
    "\n",
    "    fig = plt.figure(figsize=(22.0, 13.0))\n",
    "    plt.errorbar(x, y, yerr=yerr, fmt='o', linestyle='-', color='b')\n",
    "    plt.title('mean score for n-th most important features', fontsize=22)\n",
    "    ax = plt.gca()\n",
    "    ax.legend_ = None\n",
    "    plt.xlabel('nb of components considered ', fontsize=22)\n",
    "    plt.ylabel('scores',fontsize=22)\n",
    "    plt.legend(numpoints=1, loc=2)  # numpoints = 1 for nicer display\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0, sort_feat_import_df.shape[0]])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=200)\n",
    "clf.fit(X, y)\n",
    "weights = clf.feature_importances_\n",
    "columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explicability(weights, columns, first=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_important_features, score_mean, error_on_mean_score, sort_feat_import_df = score_with_components(\n",
    "    clf, X, y, columns, weights, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_score_with_components(most_important_features, score_mean, error_on_mean_score, sort_feat_import_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement sur un récepteur et prédiction sur un autre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       135\n",
      "        1.0       1.00      1.00      1.00       135\n",
      "\n",
      "avg / total       1.00      1.00      1.00       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "receiver = 50\n",
    "\n",
    "y = labelize(sumH, receiver)\n",
    "X = extractFeatures(sum_traces_grouped, receiver)\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=200)\n",
    "clf.fit(X, y)\n",
    "\n",
    "classification_metrics(y, clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:24<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      1.00      0.67       135\n",
      "        1.0       0.00      0.00      0.00       135\n",
      "\n",
      "avg / total       0.25      0.50      0.33       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "receiver = 51\n",
    "\n",
    "y = labelize(sumH, receiver)\n",
    "X = extractFeatures(sum_traces_grouped, receiver)\n",
    "\n",
    "classification_metrics(y, clf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction pour plusieurs récepteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fitPredictAllReceivers(receivers, sumH, sum_traces_grouped, echantillonage=2, debug=True):\n",
    "    \"\"\"\n",
    "    Entraîner et prédire un classifieur pour chaque récepteur\n",
    "    \"\"\"\n",
    "    for receiver in receivers:\n",
    "        if receiver % echantillonage == 0:\n",
    "            print(\"Recepteur %d\" %(receiver))\n",
    "            y = labelize(sumH, receiver)\n",
    "            X = extractFeatures(sum_traces_grouped, receiver)\n",
    "\n",
    "            clf = ExtraTreesClassifier(n_estimators=200)\n",
    "            y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "            \n",
    "            if debug:\n",
    "                classification_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time fitPredictAllReceivers(range(n3_convH), sumH, sum_traces_grouped, echantillonage=2, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pédiction pour plusieurs fichiers et récepteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fitPredictAllFiles(files, echantillonage=2, debug=True):\n",
    "    \"\"\"\n",
    "    Entraîner et prédire un classifieur pour chaque récepteur des fichiers\n",
    "    \"\"\"\n",
    "    for file in files:\n",
    "        print(\"Fichier %d\" %(file))\n",
    "        convH = load_data(file)\n",
    "        n_convH = normalize_signals(convH)\n",
    "        sum_traces, sum_traces_grouped = compute_sums(n_convH, n_tracesByGroups=20)\n",
    "        sumH = compute_SSE(sum_traces, sum_traces_grouped)\n",
    "        \n",
    "        fitPredictAllReceivers(range(n3_convH), sumH, sum_traces_grouped, echantillonage, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recepteur 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:24<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.83      0.84       135\n",
      "        1.0       0.83      0.84      0.84       135\n",
      "\n",
      "avg / total       0.84      0.84      0.84       270\n",
      "\n",
      "Recepteur 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:24<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.89      0.87       135\n",
      "        1.0       0.88      0.85      0.87       135\n",
      "\n",
      "avg / total       0.87      0.87      0.87       270\n",
      "\n",
      "Recepteur 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:24<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.90      0.88       135\n",
      "        1.0       0.90      0.84      0.87       135\n",
      "\n",
      "avg / total       0.88      0.87      0.87       270\n",
      "\n",
      "Recepteur 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:24<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.81      0.80       135\n",
      "        1.0       0.81      0.78      0.79       135\n",
      "\n",
      "avg / total       0.80      0.80      0.80       270\n",
      "\n",
      "Recepteur 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.73      0.73       135\n",
      "        1.0       0.73      0.73      0.73       135\n",
      "\n",
      "avg / total       0.73      0.73      0.73       270\n",
      "\n",
      "Recepteur 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.77      0.77       135\n",
      "        1.0       0.77      0.77      0.77       135\n",
      "\n",
      "avg / total       0.77      0.77      0.77       270\n",
      "\n",
      "Recepteur 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.70      0.71       135\n",
      "        1.0       0.71      0.73      0.72       135\n",
      "\n",
      "avg / total       0.72      0.72      0.72       270\n",
      "\n",
      "Recepteur 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.76      0.76       135\n",
      "        1.0       0.76      0.76      0.76       135\n",
      "\n",
      "avg / total       0.76      0.76      0.76       270\n",
      "\n",
      "Recepteur 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:24<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.81      0.80       135\n",
      "        1.0       0.81      0.78      0.79       135\n",
      "\n",
      "avg / total       0.80      0.80      0.80       270\n",
      "\n",
      "Recepteur 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.79      0.76       135\n",
      "        1.0       0.77      0.71      0.74       135\n",
      "\n",
      "avg / total       0.75      0.75      0.75       270\n",
      "\n",
      "Recepteur 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.65      0.67       135\n",
      "        1.0       0.67      0.71      0.69       135\n",
      "\n",
      "avg / total       0.68      0.68      0.68       270\n",
      "\n",
      "Recepteur 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.68      0.71      0.69       135\n",
      "        1.0       0.70      0.66      0.68       135\n",
      "\n",
      "avg / total       0.69      0.69      0.68       270\n",
      "\n",
      "Recepteur 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.76      0.76       135\n",
      "        1.0       0.76      0.76      0.76       135\n",
      "\n",
      "avg / total       0.76      0.76      0.76       270\n",
      "\n",
      "Recepteur 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.73      0.73       135\n",
      "        1.0       0.73      0.73      0.73       135\n",
      "\n",
      "avg / total       0.73      0.73      0.73       270\n",
      "\n",
      "Recepteur 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:24<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.74      0.72       135\n",
      "        1.0       0.72      0.68      0.70       135\n",
      "\n",
      "avg / total       0.71      0.71      0.71       270\n",
      "\n",
      "Recepteur 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.71      0.70       135\n",
      "        1.0       0.70      0.69      0.70       135\n",
      "\n",
      "avg / total       0.70      0.70      0.70       270\n",
      "\n",
      "Recepteur 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.79      0.76       135\n",
      "        1.0       0.77      0.73      0.75       135\n",
      "\n",
      "avg / total       0.76      0.76      0.76       270\n",
      "\n",
      "Recepteur 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:24<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.76      0.73       135\n",
      "        1.0       0.74      0.69      0.71       135\n",
      "\n",
      "avg / total       0.72      0.72      0.72       270\n",
      "\n",
      "Recepteur 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.76      0.81       135\n",
      "        1.0       0.78      0.88      0.83       135\n",
      "\n",
      "avg / total       0.82      0.82      0.82       270\n",
      "\n",
      "Recepteur 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.76      0.74       135\n",
      "        1.0       0.74      0.71      0.73       135\n",
      "\n",
      "avg / total       0.73      0.73      0.73       270\n",
      "\n",
      "Recepteur 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.93      0.93       135\n",
      "        1.0       0.93      0.94      0.93       135\n",
      "\n",
      "avg / total       0.93      0.93      0.93       270\n",
      "\n",
      "Recepteur 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:24<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.88      0.90       135\n",
      "        1.0       0.89      0.93      0.91       135\n",
      "\n",
      "avg / total       0.91      0.91      0.91       270\n",
      "\n",
      "Recepteur 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:24<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.90      0.89       135\n",
      "        1.0       0.90      0.87      0.89       135\n",
      "\n",
      "avg / total       0.89      0.89      0.89       270\n",
      "\n",
      "Recepteur 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 270/270 [00:25<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.86      0.86       135\n",
      "        1.0       0.86      0.87      0.86       135\n",
      "\n",
      "avg / total       0.86      0.86      0.86       270\n",
      "\n",
      "Recepteur 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction:  83%|████████▎ | 224/270 [00:21<00:04, 10.26it/s]Process ForkPoolWorker-305:\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-302:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-304:\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-303:\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/extraction.py\", line 504, in _extract_features_for_one_time_series\n",
      "    current_result = dataframe.groupby(column_id)[column_value].apply(apply_function, **kwargs).unstack()\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1947, in agg_series\n",
      "    return self._aggregate_series_fast(obj, func)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 694, in apply\n",
      "    return self._python_apply_general(f)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 698, in _python_apply_general\n",
      "    self.axis)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1614, in apply\n",
      "    result_values.append(res)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1952, in _aggregate_series_fast\n",
      "    func = self._is_builtin_func(func)\n",
      "AttributeError: 'BaseGrouper' object has no attribute '_is_builtin_func'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1952, in _aggregate_series_fast\n",
      "    func = self._is_builtin_func(func)\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1947, in agg_series\n",
      "    return self._aggregate_series_fast(obj, func)\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/extraction.py\", line 494, in _extract_features_for_one_time_series\n",
      "    extracted_features = dataframe.groupby(column_id)[column_value].aggregate(column_name_to_aggregate_function)\n",
      "KeyboardInterrupt\n",
      "AttributeError: 'BaseGrouper' object has no attribute '_is_builtin_func'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 2656, in aggregate\n",
      "    (_level or 0) + 1)\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 2718, in _aggregate_multiple_funcs\n",
      "    results[name] = obj.aggregate(func)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1947, in agg_series\n",
      "    return self._aggregate_series_fast(obj, func)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/extraction.py\", line 494, in _extract_features_for_one_time_series\n",
      "    extracted_features = dataframe.groupby(column_id)[column_value].aggregate(column_name_to_aggregate_function)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1952, in _aggregate_series_fast\n",
      "    func = self._is_builtin_func(func)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 2656, in aggregate\n",
      "    (_level or 0) + 1)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 2666, in aggregate\n",
      "    return self._python_agg_general(func_or_funcs, *args, **kwargs)\n",
      "AttributeError: 'BaseGrouper' object has no attribute '_is_builtin_func'\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 2718, in _aggregate_multiple_funcs\n",
      "    results[name] = obj.aggregate(func)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 820, in _python_agg_general\n",
      "    result, counts = self.grouper.agg_series(obj, f)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 2666, in aggregate\n",
      "    return self._python_agg_general(func_or_funcs, *args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1949, in agg_series\n",
      "    return self._aggregate_series_pure_python(obj, func)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 820, in _python_agg_general\n",
      "    result, counts = self.grouper.agg_series(obj, f)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1979, in _aggregate_series_pure_python\n",
      "    res = func(group)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1949, in agg_series\n",
      "    return self._aggregate_series_pure_python(obj, func)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 814, in <lambda>\n",
      "    f = lambda x: func(x, *args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/feature_calculators.py\", line 77, in func_on_nonNumberObject\n",
      "    return func(x, *arg, **args)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1979, in _aggregate_series_pure_python\n",
      "    res = func(group)\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 814, in <lambda>\n",
      "    f = lambda x: func(x, *args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/feature_calculators.py\", line 1160, in autocorrelation\n",
      "    return pd.Series.autocorr(x, lag)\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 1475, in autocorr\n",
      "    return self.corr(self.shift(lag))\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/feature_calculators.py\", line 77, in func_on_nonNumberObject\n",
      "    return func(x, *arg, **args)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 1418, in corr\n",
      "    this, other = self.align(other, join='inner', copy=False)\n",
      "  File \"/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 2350, in align\n",
      "    broadcast_axis=broadcast_axis)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/feature_calculators.py\", line 1160, in autocorrelation\n",
      "    return pd.Series.autocorr(x, lag)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/extraction.py\", line 494, in _extract_features_for_one_time_series\n",
      "    extracted_features = dataframe.groupby(column_id)[column_value].aggregate(column_name_to_aggregate_function)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 4419, in align\n",
      "    fill_axis=fill_axis)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-9b4fc7bea197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitPredictAllFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mechantillonage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-6d762be0e58e>\u001b[0m in \u001b[0;36mfitPredictAllFiles\u001b[0;34m(files, echantillonage, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msumH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_SSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_traces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_traces_grouped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mfitPredictAllReceivers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn3_convH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msumH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_traces_grouped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mechantillonage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-7fdfc056934b>\u001b[0m in \u001b[0;36mfitPredictAllReceivers\u001b[0;34m(receivers, sumH, sum_traces_grouped, echantillonage, debug)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recepteur %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreceiver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_traces_grouped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreceiver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-06d5d1de9ab2>\u001b[0m in \u001b[0;36mextractFeatures\u001b[0;34m(sum_traces_grouped, receiver)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmaster_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaster_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 75 * 270 -1 = 20 249\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_fc_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextraction_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/extraction.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(timeseries_container, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, parallelization, chunksize, n_processes, show_warnings, disable_progressbar, impute_function, profile, profiling_filename, profiling_sorting)\u001b[0m\n\u001b[1;32m    171\u001b[0m                                   \u001b[0mshow_warnings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_warnings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                                   \u001b[0mdisable_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                                   \u001b[0mimpute_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimpute_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                                   )\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/extraction.py\u001b[0m in \u001b[0;36m_extract_features_parallel_per_sample\u001b[0;34m(kind_to_df_map, column_id, column_value, default_fc_parameters, kind_to_fc_parameters, chunksize, n_processes, show_warnings, disable_progressbar, impute_function)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mmap_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_fifo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mdfs_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterable_with_tqdm_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mdf_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_kind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# Impute the result if requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.6/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m   1452\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.6/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m   1479\u001b[0m             \u001b[0mobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m             \u001b[0mobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/extraction.py\u001b[0m in \u001b[0;36miterable_with_tqdm_update\u001b[0;34m(queue, progress_bar)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# a new result is there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0miterable_with_tqdm_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m             self._taskqueue.put((((result._job, i, mapstar, (x,), {})\n\u001b[1;32m    313\u001b[0m                      for i, x in enumerate(task_batches)), result._set_length))\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     def apply_async(self, func, args=(), kwds={}, callback=None,\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 1475, in autocorr\n",
      "    return self.corr(self.shift(lag))\n",
      "\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 2656, in aggregate\n",
      "    (_level or 0) + 1)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 1422, in corr\n",
      "    min_periods=min_periods)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 4483, in _align_series\n",
      "    if self.index.equals(other.index):\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 2718, in _aggregate_multiple_funcs\n",
      "    results[name] = obj.aggregate(func)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/nanops.py\", line 50, in _f\n",
      "    return f(*args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 2666, in aggregate\n",
      "    return self._python_agg_general(func_or_funcs, *args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/nanops.py\", line 691, in nancorr\n",
      "    f = get_corr_func(method)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/nanops.py\", line 699, in get_corr_func\n",
      "    def _pearson(a, b):\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 820, in _python_agg_general\n",
      "    result, counts = self.grouper.agg_series(obj, f)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1949, in agg_series\n",
      "    return self._aggregate_series_pure_python(obj, func)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 1979, in _aggregate_series_pure_python\n",
      "    res = func(group)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/pandas/core/groupby.py\", line 814, in <lambda>\n",
      "    f = lambda x: func(x, *args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/feature_calculators.py\", line 77, in func_on_nonNumberObject\n",
      "    return func(x, *arg, **args)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/tsfresh/feature_extraction/feature_calculators.py\", line 274, in augmented_dickey_fuller\n",
      "    return adfuller(x)[0]\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/tsa/stattools.py\", line 240, in adfuller\n",
      "    maxlag, autolag)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/tsa/stattools.py\", line 85, in _autolag\n",
      "    mod_instance = mod(endog, exog[:, :lag], *modargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py\", line 526, in __init__\n",
      "    weights=weights, hasconst=hasconst, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py\", line 631, in __init__\n",
      "    hasconst=hasconst, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py\", line 95, in __init__\n",
      "    super(RegressionModel, self).__init__(endog, exog, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/base/model.py\", line 212, in __init__\n",
      "    super(LikelihoodModel, self).__init__(endog, exog, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/base/model.py\", line 63, in __init__\n",
      "    **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/base/model.py\", line 88, in _handle_data\n",
      "    data = handle_data(endog, exog, missing, hasconst, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/base/data.py\", line 630, in handle_data\n",
      "    **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/base/data.py\", line 79, in __init__\n",
      "    self._handle_constant(hasconst)\n",
      "  File \"/opt/miniconda3/lib/python3.6/site-packages/statsmodels/base/data.py\", line 131, in _handle_constant\n",
      "    const_idx = np.where(self.exog.ptp(axis=0) == 0)[0].squeeze()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "fitPredictAllFiles(some_files[:2], echantillonage=5, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
